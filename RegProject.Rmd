---
output: pdf_document
---
```{r echo=FALSE, warning=FALSE}
#options(digits=2)
library(xtable)
library(car)
library(leaps)
library(knitr)
data(mtcars)
options(digits=2)
```
#Transmission Type and Fuel Economy in the MTCARS Data Set  
## Executive Summary 
We analyzed the *mtcars* data set in R which is taken from the 1974 *Motor Trends* magazine and includes information on eleven variables for 32 automobiles. In particular, we attempted to establish the impact of transmission type (automatic vs. manual) on fuel economy measured in miles per gallon. Our final regression model included vehicle weight and quarter mile time as additional predictors. In the context of this data set, there appears to be an advantage of about 2.9 miles per gallon for manual over automatic transmissions. The 95% confidence interval on this value, though, is fairly wide, ranging from 0.05 to 5.8, just barely failing to include 0. It is important to note, though, that without knowing how the 32 automobiles in the data set were selected or what additional variables might be of importance in determining fuel economy, generalizing the specific impact of transmission type on fuel economy beyond this data set is most likely problematic.

## Exploratory Data Analysis 
Box plots for the seven variables with more than three values are show in Figure A1 in the Appendix while frequencies for the four binary or trinary variables are shown in Figure A2. The Maserati Bora appears to be an outlier with respect to horse power and number of carburetors while the Mercedes 230 has a notably longer quarter mile time. We retain these two automobiles as they are, but note that a separate analysis indicated that removing both cars from the data set had only a small effect on the final model estimates.

Correlations were computed between all pairs of variables. The resulting correlation matrix is shown in Figure A3. It is clear that there are a number of large correlations that will have to be considered in any regression analysis.

Scatterplots of mpg versus each of the other variables are shown in Figure A4. Although we do not consider quadratric terms in the current regression analysis, the curvature in the scatterplots for displacement and horsepower suggest that such terms might be worth considering in a future analysis.

##Regression Analysis 
We first fit the single-predictor model regressing mpg on only transmission type (am).
```{r comment=NA, row.names=FALSE}
fit<-lm(mpg~am,data=mtcars)
```
```{r echo=FALSE}
outp<-cbind(data.frame(summary(fit)$coefficients),data.frame(confint(fit)))
colnames(outp)<-c("Estimate","Std.Error","t value","p value","2.5%","97.5%")
kable(outp,digits=10)
noquote(paste("R-squared = ",round(summary(fit)$r.squared,digits=3),
              "      Adj.R-sq = ",round(summary(fit)$adj.r.squared,digits=3),              
              "      Res.Std.Error = ",round(summary(fit)$sigma,digits=3)))
```
The coefficient for transmission type in this model is 7.2, suggesting a 7.2 miles-per-gallon advantage of a manual transmission (coded as 1) over an automatic transmission (coded as 0). This model, though, controls for no other variables. We next fit the model with all ten predictors.  
```{r}
fit10<-lm(mpg~cyl+disp+hp+drat+wt+qsec+vs+am+gear+carb,data=mtcars)
```
.  
```{r echo=FALSE}
coefs<-summary(fit10)$coefficients
row.names(coefs)[1]<-"Int"
t(coefs)
noquote(paste("R-squared = ",round(summary(fit10)$r.squared,digits=3),
              "      Adj.R-sq = ",round(summary(fit10)$adj.r.squared,digits=3),                
              "      Res.Std.Error = ",round(summary(fit10)$sigma,digits=3)))
```
The R-squared for the full model is 0.87, much higher than the 0.36 when transmission type is the only predictor in the model. Note, though, that the coefficient for transmission type (am) has dropped from 7.2 to 2.5 and is no longer statistically significantly different from 0.

Variance inflation factors for this model are shown below. It is clear that a number of the values are quite high. This is not suprising given the considerable number of large correlations among the variables.
```{r echo=FALSE}
vif(fit10)
```
We would like to reduce the number of predictors while still accounting for as much of the variance in MPG as we can. Using the *regsubsets* function in the *leaps* package, all subsets regression was run. With 10 potential predictors, there are 2^10=1024 possible models, half of which will include transmission type. The "best" model emerging from this analysis includes transmission type (am), weight (wt), and quarter mile time (qsec) as predictors (see Figure A5). We therefore fit the model with only these three predictors.
```{r warning=FALSE, echo=FALSE}
bestreg<-regsubsets(mpg~cyl+disp+hp+drat+wt+qsec+vs+am+gear+carb,nvmax=10,data=mtcars)
```

```{r}
fit3<-lm(mpg~am+wt+qsec,data=mtcars)
```
```{r echo=FALSE}
outp<-cbind(data.frame(summary(fit3)$coefficients),data.frame(confint(fit3)))
colnames(outp)<-c("Estimate","Std.Error","t value","p value","2.5%","97.5%")
kable(outp,digits=10)

noquote(paste("R-squared = ",round(summary(fit3)$r.squared,digits=3),
              "      Adj.R-sq = ",round(summary(fit3)$adj.r.squared,digits=3),  
              "      Res.Std.Error = ",round(summary(fit3)$sigma,digits=3)))
```
The coefficient for transmission type is 2.9, suggesting a 2.9 miles-per-gallon advantage of manual over automatic transmissions. The 95% confidence interval for the coefficient is 0.05 to 5.8 and the p value testing the null hypothesis of a zero coefficient is < .05. The R-square value of 0.85 is nearly as large as that for the full ten-predictor model and the adjusted R-square value is slightly higher than for the full model. 

An ANOVA test was run comparing the ten-predictor model to the three-predictor model (using *anova(fit3,fit10)*.) The F value with 7 and 21 degrees of freedom was 0.44, yielding a p value of 0.86. These results suggest that adding the seven variables to the three-predictor model contributes very little. 
```{r echo=FALSE, results="hide"}
anova(fit3,fit10)
```


## Residuals and Diagnostics
Residual plots for the three-predictor model are presented in Figure A6. Nothing in these plots points to notable problems with our final model.  

Note: The full R markdown document is available at github.com/kbiolsi/RegressionProject/RegProject.Rmd


# Appendix


**Figure A1. Box plots for the seven numeric variables that take on at least four values.**  
```{r fig.width = 6, fig.height = 3, echo=FALSE}          
par(mfrow=c(2,4))
par(mar=c(2,3,2,2))

vars<-c(1,3,4,5,6,7,11)
for (i in vars){ boxplot(mtcars[,i],main=colnames(mtcars[i]))}
par(mfrow=c(1,1))
```
.  
.  
.  
**Figure A2. Bar plots for the four binary or trinary variables.**  
```{r fig.width = 6, fig.height = 1.5, echo=FALSE}
par(mfrow=c(1,4)); par(mar=c(2,3,2,1))
vars<-c(2,8,9,10)
for (i in vars){ t<-table(mtcars[,i]); barplot(t,main=colnames(mtcars[i]))
}
par(mfrow=c(1,1))
```
.  
.  
.  
**Figure A3. Correlation matrix for all pairs of variables.**  
```{r echo=FALSE}
cor(mtcars)
```
.  
.  
.  
**Figure A4. Scatterplots of MPG versus the ten potential predictors.**  
```{r warning=FALSE, echo=FALSE}
axisLabels<-c("# of cylinders","Displacement","Horsepower","Rear axle ratio",
              "Weight (1000 lb)","1/4 mile time","Engine shape (0=V; 1=Straight)",
              "Transmission (0=auto;1=manual)","# of gears","# of carburetors")
par(mar=c(4,0,1,1)); par(mfrow=c(3,4))
for (i in 2:11) {
    if ((i %% 4)==2) { 
        par(mar=c(4,4,1,1))
        plot(mtcars[,i],mtcars[,1],xlab=axisLabels[i-1],ylab="mpg")
    }
    else {
        par(mar=c(4,4,1,1))
        plot(mtcars[,i],mtcars[,1],xlab=axisLabels[i-1],ylab="",yaxt="n")
    }
}
par(mfrow=c(1,1))
```
.  
.  
**Figure A5. All subsets regression: models of each size with smallest Bayesian Information Criterion (BIC) value**  
```{r echo=FALSE,fig.width=6,fig.height=3.5}
par(mar=c(4,4,1,0))
res.legend <-
    subsets(bestreg, statistic="bic", legend = FALSE, min.size = 2, main = "",ylim=c(-47,-26))
rect(2.55,-47.4,3.45,-45.7,border="red",lwd=2)
```
.    
.  
.  
**Figure A6. Residual plots for three-predictor model.**  
```{r echo=FALSE, fig.width=6, fig.height=5}
par(mfrow=c(2,2))
par(mar=c(4,4,3,1))
plot(fit3)
par(mfrow=c(1,1))
```

